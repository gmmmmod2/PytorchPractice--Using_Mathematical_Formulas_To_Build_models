# é¢˜ç›®ï¼šè‡ªè¡Œå®ç°ä¸€ä¸ªç®€å•çš„å…¨è¿æ¥å±‚

> è‡ªè¡Œå®ç°ä¸€ä¸ªç®€å•çš„å…¨è¿æ¥å±‚ï¼Œç±»ä¼¼äº PyTorch ä¸­çš„ nn.Linearã€‚å®ç°æ—¶éœ€è¦è‡ªå·±å¤„ç†æƒé‡åˆå§‹åŒ–ã€å‰å‘ä¼ æ’­ã€ä»¥åŠåç½®çš„æ·»åŠ ã€‚

## æ•°å­¦å®šä¹‰

å®šä¹‰è¾“å…¥ä¸º $X \in \mathbb{R}^{B \times d_{in}}$ã€‚è¾“å‡ºç»´åº¦ä¸º $d_{out}$ï¼Œåˆ™å…¨è¿æ¥å±‚çš„è¾“å‡ºæ˜¯é€šè¿‡ä»¥ä¸‹å…¬å¼è®¡ç®—å¾—åˆ°çš„ï¼š

$$
y = W \cdot x + b
$$

å…¶ä¸­ï¼Œ$ğ‘Š$ æ˜¯æƒé‡çŸ©é˜µï¼Œ$x$ æ˜¯è¾“å…¥ï¼Œ$b$ æ˜¯åç½®é¡¹ï¼Œ$y$ æ˜¯è¾“å‡ºã€‚

## å®ç°è¦æ±‚

- å®ç° `Linear` å±‚ï¼ŒåŒ…å«æƒé‡åˆå§‹åŒ–ã€å‰å‘ä¼ æ’­å’Œåç½®é¡¹ã€‚
- æƒé‡åˆå§‹åŒ–ä½¿ç”¨æ ‡å‡†æ­£æ€åˆ†å¸ƒï¼ˆå‡å€¼ä¸º 0ï¼Œæ–¹å·®ä¸º 1ï¼‰ã€‚

## å‚è€ƒå®ç°

```python
import torch
import torch.nn as nn
import torch.nn.init as init

class MyLinear(nn.Module):
    def __init__(self, d_in, d_out):
        super().__init__()
        # å®šä¹‰æƒé‡å’Œåç½®
        self.weight = nn.Parameter(torch.randn(d_in, d_out))
        self.bias = nn.Parameter(torch.randn(d_out))

        self.reset_parameters() # è°ƒç”¨åˆå§‹åŒ–æ–¹æ³•

    def reset_parameters(self):
        init.normal_(self.weight, mean=0, std=1)  # ä½¿ç”¨æ ‡å‡†æ­£æ€åˆ†å¸ƒåˆå§‹åŒ–æƒé‡
        init.zeros_(self.bias)  # åç½®åˆå§‹åŒ–ä¸ºé›¶

    def forward(self, x):
        # å‰å‘ä¼ æ’­ï¼šy = x * W + b
        return torch.matmul(x, self.weight) + self.bias
```
