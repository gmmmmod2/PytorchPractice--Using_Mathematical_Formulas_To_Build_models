# 题目：门控线性单元（GLU）文本前馈块

**目标**：实现 GLU 前馈层，常用于替代 ReLU 前馈：$ \mathrm{GLU}(XW_1 + b_1) \odot \sigma(XW_2 + b_2)$。

## 数学定义

设输入 $X\in\mathbb{R}^{B\times L\times d}$，中间维度 $m$：

$$
H = XW_1 + b_1,\quad G = \sigma(XW_2 + b_2),\quad
Y = H \odot G \, W_o + b_o
$$

## 实现要求

- 线性层分别输出 $m$ 维与 $m$ 维 gate，再接输出投影到 $d$。
- 可选 `dropout` 与 `LayerNorm` 前后顺序（Pre-Norm）。

## 参考实现

```python
import torch
import torch.nn as nn

class GLUBlock(nn.Module):
    def __init__(self, d_model, d_hidden, dropout=0.1, prenorm=True):
        super().__init__()
        self.prenorm = prenorm
        self.ln = nn.LayerNorm(d_model)
        self.lin_h = nn.Linear(d_model, d_hidden)
        self.lin_g = nn.Linear(d_model, d_hidden)
        self.lin_o = nn.Linear(d_hidden, d_model)
        self.drop = nn.Dropout(dropout)

    def forward(self, x):
        residual = x
        if self.prenorm:
            x = self.ln(x)
        H = self.lin_h(x)
        G = torch.sigmoid(self.lin_g(x))
        y = self.lin_o(H * G)
        y = self.drop(y)
        return residual + y  # 残差

# 验证
B,L,d = 2,8,32
m = GLUBlock(d, 64)
x = torch.randn(B,L,d)
y = m(x)
print(y.shape)
```
